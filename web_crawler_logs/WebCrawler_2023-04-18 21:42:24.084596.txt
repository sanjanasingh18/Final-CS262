2023-04-18:21:42:24,085, Starting web crawler...
2023-04-18:21:42:24,085, Crawling: https://www.wtatennis.com/
2023-04-18:21:42:24,420, Finished crawling: https://www.wtatennis.com/
2023-04-18:21:42:24,420, Crawling: apps
2023-04-18:21:42:24,420, Finished crawling: apps
2023-04-18:21:42:24,421, Crawling: http://instagram.com/wta
2023-04-18:21:42:25,694, Finished crawling: http://instagram.com/wta
2023-04-18:21:42:25,694, Crawling: http://www.usopenseries.com/home/default.sps
2023-04-18:21:42:27,599, Finished crawling: http://www.usopenseries.com/home/default.sps
2023-04-18:21:42:27,599, Crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:21:42:28,082, Finished crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:21:42:28,083, Crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:21:42:28,495, Finished crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:21:42:28,495, Crawling: http://www.atpworldtour.com/
2023-04-18:21:42:28,993, Finished crawling: http://www.atpworldtour.com/
2023-04-18:21:42:28,993, Crawling: http://
2023-04-18:21:42:28,993, Failed to crawl: http://
Traceback (most recent call last):
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 107, in run_crawler
    self.crawl_url(url)
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 76, in crawl_url
    html = self.get_url_info(url)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 100, in get_url_info
    return requests.get(url).text
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 573, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 484, in prepare_request
    p.prepare(
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 445, in prepare_url
    raise InvalidURL(f"Invalid URL {url!r}: No host supplied")
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:21:42:29,011, Crawling: http://
2023-04-18:21:42:29,011, Failed to crawl: http://
Traceback (most recent call last):
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 107, in run_crawler
    self.crawl_url(url)
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 76, in crawl_url
    html = self.get_url_info(url)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 100, in get_url_info
    return requests.get(url).text
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 573, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 484, in prepare_request
    p.prepare(
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 445, in prepare_url
    raise InvalidURL(f"Invalid URL {url!r}: No host supplied")
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:21:42:29,012, Crawling: http://
2023-04-18:21:42:29,012, Failed to crawl: http://
Traceback (most recent call last):
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 107, in run_crawler
    self.crawl_url(url)
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 76, in crawl_url
    html = self.get_url_info(url)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 100, in get_url_info
    return requests.get(url).text
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 573, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 484, in prepare_request
    p.prepare(
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 445, in prepare_url
    raise InvalidURL(f"Invalid URL {url!r}: No host supplied")
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:21:42:29,013, Crawling: http://barcelonaopenbancsabadell.com
2023-04-18:21:42:30,765, Finished crawling: http://barcelonaopenbancsabadell.com
2023-04-18:21:42:30,765, Crawling: http://barcelonaopenbancsabadell.com/aviso-legal
2023-04-18:21:42:30,765, Finished crawling: http://barcelonaopenbancsabadell.com/aviso-legal
2023-04-18:21:42:30,766, Crawling: http://barcelonaopenbancsabadell.com/hospitality
2023-04-18:21:42:32,173, Finished crawling: http://barcelonaopenbancsabadell.com/hospitality
2023-04-18:21:42:32,173, Crawling: http://barcelonaopenbancsabadell.com/noticias
2023-04-18:21:42:35,543, Finished crawling: http://barcelonaopenbancsabadell.com/noticias
2023-04-18:21:42:35,543, Crawling: http://barcelonaopenbancsabadell.com/tickets
2023-04-18:21:42:36,836, Finished crawling: http://barcelonaopenbancsabadell.com/tickets
2023-04-18:21:42:36,836, Crawling: http://https://www.tennisclubroseto.it/atp.html
2023-04-18:21:42:36,843, Failed to crawl: http://https://www.tennisclubroseto.it/atp.html
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py", line 962, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 1037, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.11/3.11.2/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 975, in send
    self.connect()
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x11209a150>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //www.tennisclubroseto.it/atp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11209a150>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 107, in run_crawler
    self.crawl_url(url)
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 76, in crawl_url
    html = self.get_url_info(url)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sophiaho/CS262/Final-CS262/web_crawler.py", line 100, in get_url_info
    return requests.get(url).text
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //www.tennisclubroseto.it/atp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11209a150>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))
2023-04-18:21:42:36,855, Crawling: http://oeirasopen.pt/home
2023-04-18:21:42:41,589, Finished crawling: http://oeirasopen.pt/home
2023-04-18:21:42:41,589, Crawling: http://oeirasopen.pt/comochegar
2023-04-18:21:42:42,387, Finished crawling: http://oeirasopen.pt/comochegar
2023-04-18:21:42:42,388, Crawling: http://oeirasopen.pt/comochegar
2023-04-18:21:42:42,388, Finished crawling: http://oeirasopen.pt/comochegar
2023-04-18:21:42:42,388, Crawling: http://oeirasopen.pt/home
2023-04-18:21:42:44,102, Finished crawling: http://oeirasopen.pt/home
2023-04-18:21:42:44,103, Crawling: http://oeirasopen.pt/home
2023-04-18:21:42:45,539, Finished crawling: http://oeirasopen.pt/home
2023-04-18:21:42:45,540, Crawling: http://oeirasopen.pt/home
