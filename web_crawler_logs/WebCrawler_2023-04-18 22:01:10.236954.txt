2023-04-18:22:01:10,237, Starting web crawler...
2023-04-18:22:01:10,237, Crawling: https://www.wtatennis.com/
2023-04-18:22:01:10,763, Finished crawling: https://www.wtatennis.com/
2023-04-18:22:01:10,763, Crawling: apps
2023-04-18:22:01:10,764, Finished crawling: apps
2023-04-18:22:01:10,764, Crawling: http://instagram.com/wta
2023-04-18:22:01:12,181, Finished crawling: http://instagram.com/wta
2023-04-18:22:01:12,182, Crawling: http://www.usopenseries.com/home/default.sps
2023-04-18:22:01:12,651, Finished crawling: http://www.usopenseries.com/home/default.sps
2023-04-18:22:01:12,651, Crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:22:01:13,091, Finished crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:22:01:13,092, Crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:22:01:13,613, Finished crawling: http://t.email.usopen.org/lp/ustaProAcq
2023-04-18:22:01:13,613, Crawling: http://www.atpworldtour.com/
2023-04-18:22:01:14,119, Finished crawling: http://www.atpworldtour.com/
2023-04-18:22:01:14,119, Crawling: http://
2023-04-18:22:01:14,119, Failed to crawl: http://
Traceback (most recent call last):
  File "web_crawler.py", line 114, in run_crawler
    self.crawl_url(url)
  File "web_crawler.py", line 80, in crawl_url
    html = self.get_url_info(url)
  File "web_crawler.py", line 105, in get_url_info
    return requests.get(url).text
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 516, in request
    prep = self.prepare_request(req)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 449, in prepare_request
    p.prepare(
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 314, in prepare
    self.prepare_url(url, params)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 391, in prepare_url
    raise InvalidURL("Invalid URL %r: No host supplied" % url)
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:22:01:14,120, Crawling: http://
2023-04-18:22:01:14,121, Failed to crawl: http://
Traceback (most recent call last):
  File "web_crawler.py", line 114, in run_crawler
    self.crawl_url(url)
  File "web_crawler.py", line 80, in crawl_url
    html = self.get_url_info(url)
  File "web_crawler.py", line 105, in get_url_info
    return requests.get(url).text
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 516, in request
    prep = self.prepare_request(req)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 449, in prepare_request
    p.prepare(
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 314, in prepare
    self.prepare_url(url, params)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 391, in prepare_url
    raise InvalidURL("Invalid URL %r: No host supplied" % url)
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:22:01:14,121, Crawling: http://
2023-04-18:22:01:14,121, Failed to crawl: http://
Traceback (most recent call last):
  File "web_crawler.py", line 114, in run_crawler
    self.crawl_url(url)
  File "web_crawler.py", line 80, in crawl_url
    html = self.get_url_info(url)
  File "web_crawler.py", line 105, in get_url_info
    return requests.get(url).text
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 516, in request
    prep = self.prepare_request(req)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 449, in prepare_request
    p.prepare(
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 314, in prepare
    self.prepare_url(url, params)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/models.py", line 391, in prepare_url
    raise InvalidURL("Invalid URL %r: No host supplied" % url)
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
2023-04-18:22:01:14,122, Crawling: http://barcelonaopenbancsabadell.com
2023-04-18:22:01:16,226, Finished crawling: http://barcelonaopenbancsabadell.com
2023-04-18:22:01:16,226, Crawling: http://barcelonaopenbancsabadell.com/aviso-legal
2023-04-18:22:01:16,227, Finished crawling: http://barcelonaopenbancsabadell.com/aviso-legal
2023-04-18:22:01:16,227, Crawling: http://barcelonaopenbancsabadell.com/hospitality
2023-04-18:22:01:17,650, Finished crawling: http://barcelonaopenbancsabadell.com/hospitality
2023-04-18:22:01:17,650, Crawling: http://barcelonaopenbancsabadell.com/noticias
2023-04-18:22:01:20,991, Finished crawling: http://barcelonaopenbancsabadell.com/noticias
2023-04-18:22:01:20,991, Crawling: http://barcelonaopenbancsabadell.com/tickets
2023-04-18:22:01:22,253, Finished crawling: http://barcelonaopenbancsabadell.com/tickets
2023-04-18:22:01:22,253, Crawling: http://https://www.tennisclubroseto.it/atp.html
2023-04-18:22:01:22,260, Failed to crawl: http://https://www.tennisclubroseto.it/atp.html
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/connection.py", line 61, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/opt/anaconda3/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 670, in urlopen
    httplib_response = self._make_request(
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 392, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/anaconda3/lib/python3.8/http/client.py", line 1255, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/opt/anaconda3/lib/python3.8/http/client.py", line 1301, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/opt/anaconda3/lib/python3.8/http/client.py", line 1250, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/opt/anaconda3/lib/python3.8/http/client.py", line 1010, in _send_output
    self.send(msg)
  File "/opt/anaconda3/lib/python3.8/http/client.py", line 950, in send
    self.connect()
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py", line 187, in connect
    conn = self._new_conn()
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f8e095a8f40>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 726, in urlopen
    retries = retries.increment(
  File "/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py", line 446, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //www.tennisclubroseto.it/atp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8e095a8f40>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "web_crawler.py", line 114, in run_crawler
    self.crawl_url(url)
  File "web_crawler.py", line 80, in crawl_url
    html = self.get_url_info(url)
  File "web_crawler.py", line 105, in get_url_info
    return requests.get(url).text
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py", line 643, in send
    r = adapter.send(request, **kwargs)
  File "/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='https', port=80): Max retries exceeded with url: //www.tennisclubroseto.it/atp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8e095a8f40>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))
2023-04-18:22:01:22,271, Crawling: http://oeirasopen.pt/home
